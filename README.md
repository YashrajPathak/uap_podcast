# ğŸ™ï¸ UAP Podcast Generator â€” Multi-Agent Conversational AI Engine

**UAP Podcast** is a modular, production-grade multi-agent system built to autonomously **generate podcasts** from structured data, metrics, and context â€” producing **natural, human-like conversations** between specialized AI agents and synthesizing them into **high-quality audio**.

It brings together the power of **Large Language Models (LLMs)**, **Azure Speech Services**, and **conversational orchestration** to create data-driven, collaborative dialogue between domain experts.

---

## ğŸ§  Overview

The UAP Podcast system simulates a real-time conversation between three AI personas:

- ğŸ¤– **Agent Nexus** â€“ The **host and orchestrator**, setting context, introducing topics, and guiding the flow.
- ğŸ’¡ **Agent Reco** â€“ The **recommendation strategist**, advising on key metrics, insights, and strategic actions.
- ğŸ“Š **Agent Stat** â€“ The **data integrity specialist**, validating assumptions, checking statistical robustness, and challenging conclusions.

Each agent is powered by an LLM with a **distinct system prompt**, conversational personality, and contextual understanding. Together, they produce a seamless and insightful conversation that can be directly published as a podcast.

---

## âœ¨ Features

âœ… **Multi-Agent Conversation Flow**  
Orchestrates a structured, realistic dialogue with contextual awareness and back-and-forth dynamics.

âœ… **Natural Speech Synthesis**  
Generates lifelike audio using SSML modulation, with emphasis, emotion, and prosody for each agent.

âœ… **Context-Aware Recommendations**  
Processes structured data (JSON, metrics) and builds conversations around key trends, anomalies, and patterns.

âœ… **End-to-End Pipeline**  
From data ingestion to final `.wav` podcast and `.txt` script â€” all automated.

âœ… **Modular Architecture**  
Cleanly separated components for agents, models, utils, and services. Easy to extend, test, and scale.

âœ… **Production-Ready API**  
FastAPI-powered backend ready for integration with web apps, dashboards, or pipeline automation.

---

## ğŸ§± System Architecture

The conversation pipeline is divided into **three phases**:

1. **ğŸ¬ Initialization**  
   - `NexusAgent` introduces the podcast, outlines objectives, and highlights key metrics from input data.

2. **ğŸ’¬ Multi-Turn Dialogue**  
   - `RecoAgent` proposes recommendations.
   - `StatAgent` validates them with statistical reasoning.
   - Conversation evolves dynamically, adapting to previous turns and data insights.

3. **ğŸ§ Output Generation**  
   - All responses are converted to natural speech.  
   - Audio segments are stitched together into a final `.wav` file.  
   - Full transcript saved as `.txt`.

---

## ğŸ“‚ Folder Structure

src/ â””â”€â”€ uap_podcast/ â”œâ”€â”€ agents/ â”‚   â”œâ”€â”€ nexus_agent/ â”‚   â”‚   â”œâ”€â”€ agent.py â”‚   â”‚   â””â”€â”€ utils/ â”‚   â”‚       â”œâ”€â”€ nodes.py â”‚   â”‚       â”œâ”€â”€ state.py â”‚   â”‚       â””â”€â”€ tools.py â”‚   â”œâ”€â”€ reco_agent/ â”‚   â”‚   â”œâ”€â”€ agent.py â”‚   â”‚   â””â”€â”€ utils/ â”‚   â”‚       â”œâ”€â”€ nodes.py â”‚   â”‚       â”œâ”€â”€ state.py â”‚   â”‚       â””â”€â”€ tools.py â”‚   â””â”€â”€ stat_agent/ â”‚       â”œâ”€â”€ agent.py â”‚       â””â”€â”€ utils/ â”‚           â”œâ”€â”€ nodes.py â”‚           â”œâ”€â”€ state.py â”‚           â””â”€â”€ tools.py â”‚ â”œâ”€â”€ models/ â”‚   â”œâ”€â”€ podcast.py â”‚   â””â”€â”€ audio.py â”‚ â”œâ”€â”€ utils/ â”‚   â”œâ”€â”€ config.py â”‚   â””â”€â”€ logging.py â”‚ â”œâ”€â”€ tests/ â”‚   â”œâ”€â”€ test_agents.py â”‚   â”œâ”€â”€ test_models.py â”‚   â””â”€â”€ test_utils.py â”‚ â”œâ”€â”€ server.py â”œâ”€â”€ pyproject.toml â”œâ”€â”€ README.md â””â”€â”€ .env

---

## âš™ï¸ Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/your-org/uap_podcast.git
cd uap_podcast
pip install -r requirements.txt

Or with Poetry:

poetry install


---

ğŸ”‘ Environment Setup

Create a .env file in the root directory:

AZURE_OPENAI_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4o
OPENAI_API_VERSION=2024-05-01-preview

TENANT_ID=your_tenant_id
CLIENT_ID=your_client_id
CLIENT_SECRET=your_client_secret
SPEECH_REGION=eastus
RESOURCE_ID=your_resource_id


---

ğŸš€ Running the System

ğŸ–¥ï¸ CLI Mode (Generate Podcast Offline)

python -m uap_podcast.models.podcast

Youâ€™ll be prompted to:

Choose data files (data.json, metric_data.json, or both)

Specify conversation turns

Set duration (2â€“5 min)


Output:

ğŸ§ podcast_YYYYMMDD_HHMMSS.wav â€“ Final podcast audio

ğŸ“œ podcast_script_YYYYMMDD_HHMMSS.txt â€“ Full transcript



---

ğŸŒ API Mode (Run as a Backend Service)

Start the FastAPI server:

uvicorn uap_podcast.server:app --reload --port 8001

Available endpoints:

Endpoint	Method	Description

/generate-response	POST	Generate agent responses from system and user prompts
/generate-audio	POST	Convert text to synthesized audio
/health	GET	Health check endpoint



---

ğŸ§  Conversation Logic

Agent Roles:

Agent	Role	Focus

Nexus	Host & Moderator	Introduce, guide, and summarize
Reco	Recommendation Specialist	Suggest metric strategies and actions
Stat	Data Integrity Expert	Validate, challenge, and provide checks



---

ğŸ”Š Speech Synthesis

We use Azure Cognitive Services with SSML for lifelike speech:

ğŸ“ˆ Number emphasis: Key values are stressed.

â— Emotion triggers: Words like â€œshockingâ€ or â€œsurprisingâ€ change pitch.

â“ Questions: Rising intonation.

ğŸ’¼ Recommendations: Calm, authoritative tone.


Example SSML snippet:

<mstts:express-as style="cheerful">
  Given that ASA dropped 84.7%, we should confirm timestamp integrity before setting a target.
</mstts:express-as>


---

âœ… Quality & Safety Checks

Before finalizing any output, the system ensures:

âœ… Text â‰¤ 50 words per response

âœ… Total audio â‰¤ 5 minutes

âœ… JSON context is parsed correctly

âœ… Agent identity is validated

âœ… Fallback prompts handle edge cases safely



---

ğŸ§ª Testing

Run all unit tests:

pytest tests/

Or test specific modules:

pytest tests/test_agents.py -v
pytest tests/test_models.py -v
pytest tests/test_utils.py -v


---

ğŸ“ Roadmap

[ ] ğŸ”´ Real-time voice interaction (microphone + audio stream)

[ ] ğŸ§  Multi-agent memory (persistent state between episodes)

[ ] ğŸ¤ Dynamic interruptions and live dialogue simulation

[ ] ğŸŒ Dashboard for monitoring conversation state and metrics

[ ] ğŸ“¡ Integration with analytics pipelines for automated weekly episodes



---

ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repo


2. Create a new feature branch


3. Make changes with clear commits


4. Add/Update tests where necessary


5. Submit a pull request ğŸš€




---

ğŸ“œ License

This project is licensed under the MIT License.
See LICENSE for more details.


---

ğŸ‘¨â€ğŸ’» Maintainers

[Your Name] â€“ Lead Developer

[Your Team / Org] â€“ AI Engineering @ YourCompany



---

ğŸŒŸ Acknowledgements

This project builds upon:

Azure OpenAI

Azure Cognitive Services Speech

FastAPI

LangGraph



---

> ğŸ™ï¸ "Turning data into dialogue â€” and dialogue into decisions."
â€” UAP Podcast, 2025
